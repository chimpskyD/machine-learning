{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beleg2 - Multivariate lineare Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementieren Sie die multivariate lineare Regression mit Python und numpy in einem ipython notebook.\n",
    "Hinweis: Ihre Lösung der multivariaten linearen Regression sollte auf numpy basieren und im Prinzip mit beliebig vielen Features zurechtkommen. D.h. es muss eine vektorielle Implementierung vorgenommen werden.\n",
    "\n",
    "Benutzen Sie zur Lösung eine Kostenfunktion und das Gradientenabstiegsverfahren. Beachten Sie dabei folgende Punkte:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1: Erstellen Sie zuerst zum Testen Ihrer Lösung künstliche Datenwerte für zwei Merkmale (Features): \n",
    "\n",
    "#### X soll dabei eine Datenmatrix mit zwei Spalten sein, wobei die Werte zufällig aus einer Gleichverteilung (konstante Wahrscheinlichkeitsdichte in einem Intervall) gezogen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Aufgabe 1\n",
    "#Interval low-high\n",
    "low = 0\n",
    "high = 20\n",
    "data = 100 #Anzahl der Datensätze\n",
    "merkmale = 2 #Anzahl Spalten\n",
    "\n",
    "#Creates a matrix with normal distributed values \n",
    "myX = np.random.uniform(low,high, (data,merkmale)) #Matrix mit 2 Spalten\n",
    "\n",
    "original_X = myX.copy() #backup original matrix\n",
    "\n",
    "#Inserts in matrix myX, at index 0, a vector of ones along axis 1\n",
    "myX = np.insert(myX, 0, values=1, axis=1)\n",
    "print(\"Matrix: \")\n",
    "myX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2: Implementieren Sie die Hypothese (lineares Modell) als Python Funktion: linear_hypothesis(theta)\n",
    "\n",
    "#### Die Pythonfunktion soll dabei eine Funktion zurückgeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculates linear hypothesis\n",
    "#Parameter: array of thetas\n",
    "\n",
    "def linear_hypothesis(theta):\n",
    "    return lambda X: X.dot(theta) #Function works for any given Matrix X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 3: Generierung, Plotten und Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  a) Nutzen Sie die Funktion linear_hypothesis(theta) zum Generieren künstlicher y-Werte (Zielwerte) für Ihre Merkmalsvektoren (Zeilen von X).  Addieren Sie zusätzich ein gaussches Rauschen auf die einzelnen y-Werte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#theta array\n",
    "theta = np.array([1., 1., 1.]) \n",
    "\n",
    "#call function linear_hypothesis\n",
    "h = linear_hypothesis(theta)\n",
    "\n",
    "#Creates y values with function linear_hypothesis\n",
    "y = h(myX)\n",
    "\n",
    "print(\"Y values without Gaussian error: \")\n",
    "print(y) #len(y) == data\n",
    "\n",
    "#Defining mu and sigma for gaussian error\n",
    "mu = 0.0\n",
    "sigma = 1.5 \n",
    "\n",
    "#Adds a Gaussian error to the values\n",
    "y = y + np.random.normal(mu, sigma, data)\n",
    "\n",
    "print(\"\\nY values with Gaussian error: \")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### b) Stellen Sie die X1-X2-Y Werte in einem 3D Plot dar, siehe: http://matplotlib.org/mpl_toolkits/mplot3d/tutorial.html\n",
    "\n",
    "Tutorial von O Really:\n",
    "https://www.oreilly.com/learning/three-dimensional-plotting-in-matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting    \n",
    "x1 = myX[:,1]\n",
    "x2 = myX[:,2]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "\n",
    "ax.scatter(x1, x2, y, c='r', marker='o')\n",
    "\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "ax.set_zlabel('Y')\n",
    "plt.title(\"Data plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Implementieren Sie das Feature Scaling um neue x' Werte zu berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The function receives a vector of values and scales them in a range 0-1\n",
    "def feature_scale(vector):\n",
    "    if(np.std(vector) != 0):\n",
    "        vector = (vector-np.mean(vector))/np.std(vector)\n",
    "    return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scales a matrix \n",
    "def scale_matrix(X):\n",
    "    #skips first column of ones\n",
    "    #for i in range(1,merkmale+1):\n",
    "        #col = X[:,i]\n",
    "        #X[:,i] = feature_scale(col)\n",
    "    X = np.apply_along_axis(feature_scale, 0, X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myX = scale_matrix(myX)\n",
    "myX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myX[1].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myX.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1.,1.,0.5,0.1,-0.4,-0.9,-1])\n",
    "\n",
    "np.ceil(arr.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 4: Implementieren Sie die Kostenfunktion J als Python Funktion: cost_function(x, y)\n",
    "#### Die Pythonfunktion soll dabei eine Funktion zurückgeben, die die denParametervektor theta aufnimmt.\n",
    "- j = cost_function(X, y) \n",
    "- print j(theta)\n",
    "- 41.20 # Wert abhaengig von X und y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufgabe 4\n",
    "#given a matrix and hypothesis values (y values) calculate the cost function\n",
    "def cost_function(X,y):\n",
    "    m = data\n",
    "    return lambda theta: 1./(2*m)*((linear_hypothesis(theta)(X)-y)**2).sum()\n",
    "\n",
    "\n",
    "j = cost_function(myX,y) #y values not scaled\n",
    "print(j(theta)) #theta=[1,1,1]\n",
    "\n",
    "##### das ist die Kostenfuntkion mit skalierten y-Werten, mit theta=1,1,1 kommt 0.0 als Ergebnis raus!!!!!\n",
    "#thetas = [1.2,2,4]\n",
    "#jj = cost_function(myX,y_scaled)\n",
    "#print(jj(thetas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 5: Implementieren Sie das Gradientenabstiegsverfahren unter Benutzung der Kostenfunktion und der linearen Hypothese."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5a) Schreiben Sie eine Funktion die die Update Rules anwendet zur Berechnung der neuen theta-Werte:\n",
    "theta = compute_new_theta(x, y, theta, alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_new_theta(X,y,theta,alpha):\n",
    "    m = data\n",
    "    new_thetas = theta-alpha*(1.0/m)*np.dot(X.T,((linear_hypothesis(theta)(X))-y))\n",
    "    return new_thetas\n",
    "\n",
    "#Test method call with alpha 0.02 or 0.1\n",
    "print(compute_new_theta(myX,y,theta, 0.02))    \n",
    "print(compute_new_theta(myX,y,theta, 0.1))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5b) Wählen Sie Startwerte in der Umgebung des Miniums der Kostenfunktion für theta. \n",
    "#Wenden Sie iterativ die compute_new_theta Funktion an und finden Sie so ein Theta mit niedrigen Kosten.\n",
    "Kapseln Sie dies in eine Funktion:\n",
    "gradient_descent(alpha, theta, nb_iterations, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(alpha, theta, nb_iterations, X, y):\n",
    "    #Stores costs for each iteration\n",
    "    costs = [] #cost = np.zeros(nb_iterations)\n",
    "       \n",
    "    #stores changes in theta for each iteration\n",
    "    temp_thetas = np.matrix(np.zeros(myX.shape))\n",
    "    #print(temp_thetas)\n",
    "    \n",
    "    #starting cost value\n",
    "    j = cost_function(X,y)(theta)\n",
    "    \n",
    "    costs.append(j)   \n",
    "    \n",
    "    #Iterates all nb_iterations\n",
    "    for i in range(nb_iterations-1):\n",
    "        #compute new thetas\n",
    "        temp_thetas = compute_new_theta(X,y,theta,alpha)\n",
    "        #update\n",
    "        theta = temp_thetas\n",
    "        #new cost function is computed   \n",
    "        j = cost_function(X,y)\n",
    "        cost = j(theta)\n",
    "        #new cost appended\n",
    "        costs.append(cost)\n",
    "\n",
    "    return {'theta': theta, \"costs\": costs, \"last\": costs[len(costs)-1]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterations = 600\n",
    "alpha = 0.01\n",
    "theta = [0.,0.,0.]\n",
    "gr1 = gradient_descent(alpha, theta, iterations, myX, y)\n",
    "computed_theta = gr1['theta']\n",
    "#print(gr1['costs'])#last cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5c) Plotten Sie den Fortschritt (Verringerung der Kosten über den Iterationen) für 5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufgabe 5c\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "plt.plot(gr1['costs'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Stellen Sie die gefundene Hyperebene in einem 3D Plot zusammen mit den Daten dar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieves column X1 and X2 from original matrix myX\n",
    "X1 =myX[:,[1,]].flatten()#selection of all rows. Of each row then the first column\n",
    "X2 =myX[:,[2,]].flatten()\n",
    "\n",
    "#Creates a meshgrid of the matrix columns X1 and X2 \n",
    "X1mesh, X2mesh = np.meshgrid(X1,X2)\n",
    "matrixMeshed = np.column_stack((X1mesh.ravel(),X2mesh.ravel()))\n",
    "matrixMeshed = np.insert(matrixMeshed, 0, values=1, axis=1) #füge 1 als erste Spalte ein\n",
    "\n",
    "#Values for Z calculated with linear_hypothesis on the last computed thetas (gr1 above)\n",
    "yvalues = np.apply_along_axis(linear_hypothesis(computed_theta), 1, matrixMeshed) \n",
    "yvalues = yvalues.reshape(X1mesh.shape) #yvalues gets the shape of X1mesh (data,data)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "%matplotlib notebook\n",
    "#ax.plot_wireframe(X1mesh, X2mesh, yvalues, rstride=4, cstride=4, alpha=0.4)\n",
    "ax.plot_surface(X1mesh, X2mesh , yvalues, cmap='Oranges_r', alpha=0.01)\n",
    "ax.scatter(X1,X2,y, c='r')\n",
    "plt.title(\"3D Plot\")\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "ax.set_zlabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test mit mehreren Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = 0\n",
    "high = 50\n",
    "cols = 100 #features\n",
    "row = 50\n",
    "grossX = np.random.uniform(low,high, (row,cols))\n",
    "grossX = np.insert(grossX, 0, values=1, axis=1)\n",
    "#print(grossX)\n",
    "thetas = np.ones(cols+1)\n",
    "h = linear_hypothesis(thetas)\n",
    "y_val = h(grossX)\n",
    "y_val = y_val +np.random.normal(0, 1.5, row)\n",
    "\n",
    "iterations = 2500\n",
    "alpha = 0.00002\n",
    "grr = gradient_descent(alpha, thetas, iterations, grossX, y_val)\n",
    "computed_theta = grr['theta']\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(grr['costs'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
